---
title: "Impact of Dataset Size on Classification Performance: An Empirical Evaluation in the Medical Domain"
date: 2023-12-06 11:46:30
categories:
- 論文閱讀
- Dataset Evaluation
cover: /img/img-paper01-cover.webp
---

## 摘要
這篇論文主要在談資料集大小對於分類問題的影響，研究的主要發現是以下幾點：
1. Classifier的整體性能更多依賴於數據集原始的分布情況，而非數據集大小。
2. 在有限的數據下，adaboost與naive bayes最為穩定，其次為SVM -> RF -> DT。
3. 即使某個模型對於有限的數據表現最為穩定，但不能意味他性能是最好的。

{% label 反思 blue %}我認為數據集分布的重要性大於數據集大小是很正常的，畢竟資料鮮少有完美分布的情形，就像常態分布下會有超過半數都是類似的資料，反而可能影響模型訓練。

---

## 介紹
接下來作者介紹了目前這個領域的研究趨勢，大部分都是以在小資料集提升模型精準度為主，例如特徵擴展、模糊規則生成等等，較少人探討資料集大小對於模型性能的影響。

<img src="/img/img-paper01-table01.png" width=400 />


## 方法

{% label GOAL orange %} 研究資料集大小對分類性能的影響，並推薦適合用於小型資料集的分類器。
作者從UCI選了20個資料集：
<img src="/img/img-paper01-table02.png" width=400 />

並且將大型的資料集依照小型資料集的大小，切成三個大小的子集，分別為980, 490, 98並以以下參數進行訓練：
<img src="/img/img-paper01-table03.png" width=400 />

對於前18個資料集(小資料集，不包含剛剛的子集)的結果如下：
<img src="/img/img-paper01-table04.png" width=400 />
這邊作者的結論是同一個分類器在不同的資料集上的誤差是很大的，因此證明資料分布對於模型的影響很大。
{% label 反思 blue %}疑疑疑這不是很正常嗎(☉д⊙)!!!

---

大型資料集的訓練結果則如下：
<img src="/img/img-paper01-table05.png" />

這裡可以觀察到以下幾點：
1. 性能隨著資料集大小變化：大多數分類器在數據集大小減少時，表現出類似的性能下降趨勢。
2. AB模型的反應：在糖尿病數據集大小減少時，AB模型的性能有所提高。
3. 不同資料集的最佳分類器不同：SVM與NN在糖尿病中表現最佳，而RF、DT和NN則在皮膚資料集表現最佳。

{% label 反思 blue %} 作者並沒有提出為什麼AB模型有這樣的行為，我在想有幾個可能，
1. Adaboost是集成學習，他藉由多個弱分類器來構建，在較小的資料集上，簡單的模型常常會表現的比複雜的模型要更好(Overfitting問題)，因此由於弱分類器太過簡單，使得在資料集更小的時候分數有所上升，其實這是一個Adaboost不適合這個資料集的反應。
2. 作者只對這些子資料集做了一次實驗，我認為應該要重複採樣多次子資料集並實驗才能更具有說服力，尤其是作者本身的觀點就是「資料分布」的重要性，更該在實驗中體現這點。

---

## 結論：探索數據集大小對醫療領域機器學習模型性能的影響

近年來，隨著自動化診斷和個性化醫療服務的興起，對於醫療數據的需求日益增加。然而，這些先進服務的成功，往往掛鉤於數據集的豐富與否。此研究正是在這樣的背景下誕生，目的在於深入探索數據集大小對於六種廣泛應用於醫療領域的監督式機器學習模型性能的影響。

透過對包括支持向量機（SVM）、神經網絡（NN）、決策樹（DT）、隨機森林（RF）、Adaboost（AB）和朴素貝葉斯（NB）等六種分類模型的廣泛測試，作者對二十個來自醫療領域的UCI數據集進行了深入分析。此外，實施了三種不同的數據集大小減少情景，以探究模型性能隨數據集大小變化的情況。

研究結果揭示了幾個引人入勝的觀點。首先，一個顯著的發現是，分類器的整體性能並非僅受數據集大小的影響，更重要的是數據集在多大程度上能夠代表原始分布。這意味著，在醫療數據分析時，質量勝於量量。

其次，在有限的醫療數據條件下，AB和NB模型顯示出最高的穩定性，其次是SVM，再其次是RF和NN，而DT模型則是最不穩定的。這一發現提示在特定的數據環境下，選擇合適的機器學習模型至關重要。

最後，一個有趣的觀察是，即使是在有限數據集上表現穩定的模型，也不一定能夠提供比其他模型更優異的性能。這表明在應用機器學習模型時，不能僅僅關注某一個性能指標，而應該綜合考慮多個方面。

